{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83f7b77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "971ecbd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version: 3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)] \n",
      "\n",
      "Matplotlib Version: 3.3.4\n",
      "Numpy Version: 1.20.1\n",
      "Pandas Version: 1.2.4\n",
      "Scipy Version: 1.6.2\n",
      "Sklearn Version: 0.24.1\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import matplotlib\n",
    "import sys\n",
    "import scipy\n",
    "libraries = (('Matplotlib', matplotlib), ('Numpy', np), ('Pandas', pd), ('Scipy', scipy), ('Sklearn', sklearn))\n",
    "\n",
    "print(\"Python Version:\", sys.version, '\\n')\n",
    "for lib in libraries:\n",
    "    print('{0} Version: {1}'.format(lib[0], lib[1].__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9baa03b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    \"\"\"\n",
    "    Get some data, either pretend user data or the Iris dataset\n",
    "    ------\n",
    "    \"\"\"\n",
    "    # An oversimplified dataset for easy visualization while learning\n",
    "#     headers = ['referral','country','faq','age','service']\n",
    "#     my_data=[['slashdot','USA','yes',18,'None'],\n",
    "#         ['google','France','yes',17,'Premium'],\n",
    "#         ['google','France','yes',20,'Premium'],\n",
    "#         ['reddit','USA','yes',24,'Basic'],\n",
    "#         ['wiki','France','yes',23,'Basic'],\n",
    "#         ['google','UK','no',21,'Premium'],\n",
    "#         ['(direct)','New Zealand','no',12,'None'],\n",
    "#         ['(direct)','UK','no',21,'Basic'],\n",
    "#         ['google','USA','no',24,'Premium'],\n",
    "#         ['slashdot','France','yes',19,'None'],\n",
    "#         ['slashdot','UK','yes',31,'Basic'],\n",
    "#         ['reddit','USA','no',18,'None'],\n",
    "#         ['google','UK','no',18,'None'],\n",
    "#         ['wiki','UK','no',19,'None'],\n",
    "#         ['reddit','New Zealand','yes',12,'Basic'],\n",
    "#         ['slashdot','UK','no',21,'None'],\n",
    "#         ['google','UK','yes',18,'Basic'],\n",
    "#         ['wiki','France','yes',19,'Basic']]\n",
    "#     my_data = np.array(my_data)\n",
    "#     X = my_data.T[:4]\n",
    "#     y = my_data.T[-1]\n",
    "#     return X.T,y.T\n",
    "    # The Iris data set from SKLearn \n",
    "    # (http://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html)\n",
    "    from sklearn.datasets import load_iris\n",
    "    iris = load_iris()\n",
    "    return iris.data, iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9504b6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "class decision_tree_classifier:\n",
    "    \n",
    "    def __init__(self, max_depth = None):\n",
    "        \"\"\"\n",
    "        Builds a decision tree to classify target data. The\n",
    "        decision tree is built by trying to minimize the requested\n",
    "        criteria at each possible split. Starting with the whole data\n",
    "        the tree will try every possible split (column and value pair)\n",
    "        and choose the split which results in the greatest reduction \n",
    "        of the criteria. Then for each sub-group of that split, the \n",
    "        process is repeated recursively until no more splits are possible\n",
    "        or no splits cause a reduction of the criteria. In this class\n",
    "        entropy is used as the criteria.\n",
    "        ---\n",
    "        KWargs:\n",
    "        max_depth: how many splits to allow in the tree (depth not breadth)\n",
    "        \"\"\"\n",
    "        self.tree = self.tree_split()\n",
    "        self.max_depth = max_depth\n",
    "    \n",
    "    # Sub class for handling recursive nodes (only makes sense in the scope of a tree)\n",
    "    class tree_split:\n",
    "        \"\"\"\n",
    "        A sub class for handling recursive nodes. Each node will contain the value and column\n",
    "        for the current split, as well as links to the resulting nodes from the split. The \n",
    "        results attribute remains empty unless the current node is a leaf. \n",
    "        \"\"\"\n",
    "        def __init__(self,col=-1,value=None,results=None,label=None,tb=None,fb=None):\n",
    "            self.col=col # column index of criteria being tested\n",
    "            self.value=value # vlaue necessary to get a true result\n",
    "            self.results=results # dict of results for a branch, None for everything except endpoints\n",
    "            self.tb=tb # true decision nodes \n",
    "            self.fb=fb # false decision nodes\n",
    "    \n",
    "    def split_data(self, X, y, colnum, value):\n",
    "        \"\"\"\n",
    "        Returns: Two sets of data from the initial data. Set 1 contains those that passed\n",
    "        the condition of data[colnum] >= value\n",
    "        ----------\n",
    "        Input: The dataset, the column to split on, the value on which to split\n",
    "        \"\"\"\n",
    "        splitter = None\n",
    "        if isinstance(value, int) or isinstance(value,float):\n",
    "            splitter = lambda x: x[colnum] >= value\n",
    "        else:\n",
    "            splitter = lambda x: x[colnum] == value\n",
    "        split1 = [i for i,row in enumerate(X) if splitter(row)]\n",
    "        split2 = [i for i,row in enumerate(X) if not splitter(row)]\n",
    "        set1X = X[split1]\n",
    "        set1Y = y[split1]\n",
    "        set2X = X[split2]\n",
    "        set2Y = y[split2]\n",
    "        return set1X, set1Y, set2X, set2Y\n",
    "\n",
    "    def count_target_values(self, data):\n",
    "        \"\"\"\n",
    "        Returns: A dictionary of target variable counts in the data\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        counts = np.unique(data, return_counts=True)\n",
    "        for i,j in zip(*counts):\n",
    "            results[i] = j\n",
    "        return results\n",
    "\n",
    "    def entropy(self, y):\n",
    "        \"\"\"\n",
    "        Returns: Entropy of the data set, based on target values. \n",
    "        ent = Sum(-p_i Log(p_i), i in unique targets) where p is the percentage of the\n",
    "        data with the ith label.\n",
    "        Sidenote: We're using entropy as our measure of good splits. It corresponds to \n",
    "        information gained by making this split. If the split results in only one target type\n",
    "        then the entropy new sets entropy is 0. If it results in a ton of different targets, the\n",
    "        entropy will be high. \n",
    "        \"\"\"\n",
    "        results = self.count_target_values(y)\n",
    "        log_base = len(results.keys())\n",
    "        if log_base < 2:\n",
    "            log_base = 2\n",
    "        logb=lambda x:math.log(x)/math.log(log_base)\n",
    "        ent=0.\n",
    "        for r in results.keys():\n",
    "            p=float(results[r])/len(y) \n",
    "            ent-=p*logb(p)\n",
    "        return ent  \n",
    "    \n",
    "    def pandas_to_numpy(self, x):\n",
    "        \"\"\"\n",
    "        Checks if the input is a Dataframe or series, converts to numpy matrix for\n",
    "        calculation purposes.\n",
    "        ---\n",
    "        Input: X (array, dataframe, or series)\n",
    "        Output: X (array)\n",
    "        \"\"\"\n",
    "        if type(x) == type(pd.DataFrame()) or type(x) == type(pd.Series()):\n",
    "            return x.as_matrix()\n",
    "        if type(x) == type(np.array([1,2])):\n",
    "            return x\n",
    "        return np.array(x) \n",
    "    \n",
    "    def handle_1d_data(self,x):\n",
    "        \"\"\"\n",
    "        Converts 1 dimensional data into a series of rows with 1 columns\n",
    "        instead of 1 row with many columns.\n",
    "        \"\"\"\n",
    "        if x.ndim == 1:\n",
    "            x = x.reshape(-1,1)\n",
    "        return x\n",
    "    \n",
    "    def convert_to_array(self, x):\n",
    "        \"\"\"\n",
    "        Takes in an input and converts it to a numpy array\n",
    "        and then checks if it needs to be reshaped for us\n",
    "        to use it properly\n",
    "        \"\"\"\n",
    "        x = self.pandas_to_numpy(x)\n",
    "        x = self.handle_1d_data(x)\n",
    "        return x\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Helper function to wrap the fit method. This makes sure the full nested, \n",
    "        recursively built tree gets assigned to the correct variable name and \n",
    "        persists after training.\n",
    "        \"\"\"\n",
    "        self.tree = self._fit(X,y)\n",
    "    \n",
    "    def _fit(self, X, y, depth=0):\n",
    "        \"\"\"\n",
    "        Builds the decision tree via a greedy approach, checking every possible\n",
    "        branch for the best current decision. Decision strength is measured by\n",
    "        information gain/entropy reduction. If no information gain is possible,\n",
    "        sets a leaf node. Recursive calls to this method allow the nesting. If\n",
    "        max_depth is met, all further nodes become leaves as well.\n",
    "        ---\n",
    "        Input: X (feature matrix), y (labels)\n",
    "        Output: A nested tree built upon the node class.\"\"\"\n",
    "        X = self.convert_to_array(X)\n",
    "        y = self.convert_to_array(y)\n",
    "\n",
    "        if len(X) == 0: return tree_split()\n",
    "        current_score = self.entropy(y)\n",
    "\n",
    "        best_gain = 0.0\n",
    "        best_criteria = None\n",
    "        best_sets = None\n",
    "        \n",
    "        self.data_cols = X.shape[1]\n",
    "        \n",
    "        \n",
    "        # Here we go through column by column and try every possible split, measuring the\n",
    "        # information gain. We keep track of the best split then use that to send the split\n",
    "        # data sets into the next phase of splitting.\n",
    "        \n",
    "        for col in range(self.data_cols):\n",
    "            \n",
    "            # find different values in this column\n",
    "            column_values = set(X.T[col])\n",
    "            # for each possible value, try to divide on that value\n",
    "            for value in column_values:\n",
    "                set1, set1_y, set2, set2_y = self.split_data(X, y, col, value)\n",
    "\n",
    "                # Information gain\n",
    "                p = float(len(set1)) / len(y)\n",
    "                gain = current_score - p*self.entropy(set1_y) - (1-p)*self.entropy(set2_y)\n",
    "                if gain > best_gain and len(set1_y) and len(set2_y):\n",
    "                    best_gain = gain\n",
    "                    best_criteria = (col, value)\n",
    "                    best_sets = (np.array(set1), np.array(set1_y), np.array(set2), np.array(set2_y))\n",
    "        \n",
    "        \n",
    "        # Now decide whether it's an endpoint or we need to split again.\n",
    "        if (self.max_depth and depth < self.max_depth) or not self.max_depth:\n",
    "            if best_gain > 0:\n",
    "                true_branch = self._fit(best_sets[0], best_sets[1], depth=depth+1)\n",
    "                false_branch = self._fit(best_sets[2], best_sets[3], depth=depth+1)\n",
    "                return self.tree_split(col=best_criteria[0], value=best_criteria[1],\n",
    "                        tb=true_branch, fb=false_branch)\n",
    "            else:\n",
    "                return self.tree_split(results=self.count_target_values(y))\n",
    "        else:\n",
    "            return self.tree_split(results=self.count_target_values(y))\n",
    "\n",
    "    def print_tree(self, indent=\"---\"):\n",
    "        \"\"\"\n",
    "        Helper function to make sure the correct tree gets printed.\n",
    "        ---\n",
    "        In: indent (how to show splits between nodes)\n",
    "        \"\"\"\n",
    "        self.__original_indent = indent\n",
    "        self._print_tree_(self.tree, indent)\n",
    "    \n",
    "    def _print_tree_(self, tree, indent):\n",
    "        \"\"\"\n",
    "        Goes through node by node and reports the column and value used to split\n",
    "        at that node. All sub-nodes are drawn in sequence below the node.\n",
    "        \"\"\"\n",
    "        if tree.results: # if this is a end node\n",
    "            print(str(tree.results))\n",
    "        else:\n",
    "            print('Column ' + str(tree.col)+' : '+str(tree.value)+'? ')\n",
    "            # Print the branches\n",
    "            print(indent+' True: ', end=' ')\n",
    "            next_indent = indent+self.__original_indent\n",
    "            self._print_tree_(tree.tb,indent=next_indent)\n",
    "            print(indent+' False: ', end=' ')\n",
    "            self._print_tree_(tree.fb,indent=next_indent)\n",
    "\n",
    "    def predict(self, newdata):\n",
    "        \"\"\"\n",
    "        Helper function to make sure the correct tree is used to\n",
    "        make predictions. Also manages multiple rows of input data\n",
    "        since the tree must predict one at a time.\n",
    "        ---\n",
    "        In: new data point of the same structure as the training X.\n",
    "        Out: numpy array of the resulting predictions\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        for x in newdata:\n",
    "            results.append(self._predict(x,self.tree))\n",
    "        return np.array(results)\n",
    "            \n",
    "    def _predict(self, newdata, tree):\n",
    "        \"\"\"\n",
    "        Uses the reusive structure of the tree to follow each split for\n",
    "        a new data point. If the node is an endpoint, the available classes\n",
    "        are sorted by \"most common\" and then the top choice is returned.\n",
    "        \"\"\"\n",
    "        newdata = self.pandas_to_numpy(newdata)\n",
    "        if tree.results: # if this is a end node\n",
    "            return sorted(list(tree.results.items()), key=lambda x: x[1],reverse=True)[0][0]\n",
    "\n",
    "        if isinstance(newdata[tree.col], int) or isinstance(newdata[tree.col],float):\n",
    "            if newdata[tree.col] >= tree.value:\n",
    "                return self._predict(newdata, tree.tb)\n",
    "\n",
    "            else:\n",
    "                return self._predict(newdata, tree.fb)\n",
    "        else:\n",
    "            if newdata[tree.col] == tree.value:\n",
    "                return self._predict(newdata, tree.tb)\n",
    "            else:\n",
    "                return self._predict(newdata, tree.fb) \n",
    "\n",
    "    def score(self, X, y):\n",
    "        \"\"\"\n",
    "        Uses the predict method to measure the accuracy of the model.\n",
    "        ---\n",
    "        In: X (list or array), feature matrix; y (list or array) labels\n",
    "        Out: accuracy (float)\n",
    "        \"\"\"\n",
    "        pred = self.predict(X)\n",
    "        correct = 0\n",
    "        for i,j in zip(y,pred):\n",
    "            if i == j:\n",
    "                correct+=1\n",
    "        return float(correct)/float(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed218e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.4 3.7 1.5 0.2]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "X,y = get_data()\n",
    "print(X[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5377dc0b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'as_matrix'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-c97a1e24d38b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecision_tree_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-ef5b53fd38ae>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[0mpersists\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         \"\"\"\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-ef5b53fd38ae>\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, depth)\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[0mInput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfeature\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         Output: A nested tree built upon the node class.\"\"\"\n\u001b[1;32m--> 140\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-ef5b53fd38ae>\u001b[0m in \u001b[0;36mconvert_to_array\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[0mto\u001b[0m \u001b[0muse\u001b[0m \u001b[0mit\u001b[0m \u001b[0mproperly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \"\"\"\n\u001b[1;32m--> 118\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpandas_to_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle_1d_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-ef5b53fd38ae>\u001b[0m in \u001b[0;36mpandas_to_numpy\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     96\u001b[0m         \"\"\"\n\u001b[0;32m     97\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5463\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5464\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5465\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5467\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'as_matrix'"
     ]
    }
   ],
   "source": [
    "dt = decision_tree_classifier(max_depth=5)\n",
    "dt.fit(pd.DataFrame(X),pd.Series(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acf9c6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
